{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG_NAMES = {\n",
    "    '1': {\n",
    "        1: \"stop2b1000_neutralino300\",\n",
    "        2: \"glgl1400_neutralino1100\",\n",
    "        28: \"monojet_Zp2000.0_DM_50.0\",\n",
    "        29: \"glgl1600_neutralino800\",\n",
    "        30: \"monotop_200_A\",\n",
    "        31: \"stlp_st1000\",\n",
    "        32: \"sqsq_sq1800_neut800\",\n",
    "        33: \"sqsq1_sq1400_neut800\",\n",
    "        999: \"Secret\"\n",
    "    },\n",
    "    '2a': {\n",
    "        25: \"chaneut_cha250_neut150\",\n",
    "        26: \"chaneut_cha400_neut200\",\n",
    "        27: \"pp24mt_50\",\n",
    "        28: \"pp23mt_50\",\n",
    "        29: \"gluino_1000.0_neutralino_1.0\",\n",
    "        30: \"chaneut_cha200_neut50\",\n",
    "        31: \"chaneut_cha300_neut100\",\n",
    "        999: \"Secret\"\n",
    "    },\n",
    "    '2b': {\n",
    "        1: \"pp24mt_50\",\n",
    "        2: \"chaneut_cha200_neut50\",\n",
    "        3: \"stlp_st1000\",\n",
    "        4: \"chacha_cha600_neut200\",\n",
    "        5: \"pp23mt_50\",\n",
    "        6: \"chaneut_cha250_neut150\",\n",
    "        7: \"chacha_cha400_neut60\",\n",
    "        34: \"gluino_1000.0_neutralino_1.0\",\n",
    "        35: \"chacha_cha300_neut140\",\n",
    "        999: \"Secret\"\n",
    "    },\n",
    "    '3': {\n",
    "        1: \"glgl1600_neutralino800\",\n",
    "        2: \"monojet_Zp2000.0_DM_50.0\",\n",
    "        3: \"gluino_1000.0_neutralino_1.0\",\n",
    "        4: \"stop2b1000_neutralino300\",\n",
    "        5: \"sqsq1_sq1400_neut800\",\n",
    "        6: \"monotop_200_A\",\n",
    "        7: \"monoV_Zp2000.0_DM_1.0\",\n",
    "        8: \"stlp_st1000\",\n",
    "        34: \"sqsq_sq1800_neut800\",\n",
    "        35: \"glgl1400_neutralino1100\",\n",
    "        999: \"Secret\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_auc(bkg_events, sig_events):\n",
    "    # bkg_events is a 1D array of anomaly scores for the background dataset\n",
    "    # sig_events is a 1D array of anomaly scores for the signal dataset\n",
    "    # Returns: Area under the ROC curve, and signal efficiencies for three background efficiencies: 10^-2, 10^-3, 10^-4\n",
    "\n",
    "    #Create background and signal labels\n",
    "    bkg_labels = np.zeros(len(bkg_events))\n",
    "    sig_labels = np.ones(len(sig_events))\n",
    "    \n",
    "    #stitch all results together\n",
    "    events = np.append(bkg_events, sig_events)\n",
    "    labels = np.append(bkg_labels, sig_labels)\n",
    "\n",
    "    #Build ROC curve using sklearns roc_curve function\n",
    "    FPR, TPR, thresholds = roc_curve(labels, events)\n",
    "\n",
    "    #Calculate area under the ROC curve\n",
    "    AUC = auc(FPR, TPR)\n",
    "\n",
    "    #background efficiencies\n",
    "    efficiency1 = 10.0**-2\n",
    "    efficiency2 = 10.0**-3\n",
    "    efficiency3 = 10.0**-4\n",
    "    #epsilon values\n",
    "    epsilon1 = 0.0\n",
    "    epsilon2 = 0.0\n",
    "    epsilon3 = 0.0\n",
    "    #flags to tell when done\n",
    "    done1 = False\n",
    "    done2 = False\n",
    "    done3 = False\n",
    "\n",
    "    #iterate through bkg efficiencies and get as close as possible to the desired efficiencies.\n",
    "    for i in range(len(FPR)):\n",
    "        bkg_eff = FPR[i]\n",
    "        if bkg_eff >= efficiency1 and done1 == False:\n",
    "            epsilon1 = TPR[i]\n",
    "            done1 = True\n",
    "        if bkg_eff >= efficiency2 and done2 == False:\n",
    "            epsilon2 = TPR[i]\n",
    "            done2 = True\n",
    "        if bkg_eff >= efficiency3 and done3 == False:\n",
    "            epsilon3 = TPR[i]\n",
    "            done3 = True\n",
    "\n",
    "        if done1 and done2 and done3:\n",
    "            break\n",
    "            \n",
    "    return AUC, epsilon1, epsilon2, epsilon3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AND/OR scores and stuff\n",
    "algorithms = ['fixed-mse', 'flow']\n",
    "\n",
    "def calculate_metrics(resultname, bg_vae, sig_vae, bg_flow, sig_flow, calc_type=False):\n",
    "    all_bkg_ascores = np.array([bg_vae, bg_flow])\n",
    "    all_sig_ascores = np.array([sig_vae, sig_flow])\n",
    "    \n",
    "    N = 10000 \n",
    "    nbkg = len(all_bkg_ascores[0])\n",
    "    nsig = len(all_sig_ascores[0])\n",
    "    x_bkg = np.linspace(0,1,nbkg)\n",
    "    x_sig = np.linspace(0,1,nsig)\n",
    "\n",
    "    new_sig_ascores = np.full((len(algorithms), nsig), float(9999))\n",
    "    new_bkg_ascores = np.full((len(algorithms), nbkg), float(9999))\n",
    "    CDF_binned = np.full(N, float(9999))\n",
    "    \n",
    "    for i in range(len(algorithms)): # normalise each algorithm to uniform background rate\n",
    "        bkg_hist, bins = np.histogram(all_bkg_ascores[i], bins = N)\n",
    "        for j in range(N):\n",
    "            CDF_binned[j] = sum(bkg_hist[j:])/nbkg\n",
    "        x = bins[:-1]\n",
    "\n",
    "        CDF = UnivariateSpline(x, CDF_binned, s = 0) #create a function mapping x -> bkg efficiency at x\n",
    "\n",
    "        # clip signal points outside range!! if you don't do this you'll get background efficiencies greater (less) than 1 (0).\n",
    "        new_sig_ascores[i] = 1 - CDF(np.clip(all_sig_ascores[i], min(all_bkg_ascores[i]), max(all_bkg_ascores[i])))\n",
    "        new_bkg_ascores[i] = 1 - CDF(all_bkg_ascores[i])\n",
    "\n",
    "    AND_sig = np.full(nsig, float(9999))\n",
    "    AND_bkg = np.full(nbkg, float(9999))\n",
    "    OR_sig = np.full(nsig, float(9999))\n",
    "    OR_bkg = np.full(nbkg, float(9999))\n",
    "    PROD_sig = np.full(nsig, float(9999))\n",
    "    PROD_bkg = np.full(nbkg, float(9999))\n",
    "    AVG_sig = np.full(nsig, float(9999))\n",
    "    AVG_bkg = np.full(nbkg, float(9999))\n",
    "    for i in range(nsig):\n",
    "        AND_sig[i] = min(new_sig_ascores[:,i])\n",
    "        OR_sig[i] = max(new_sig_ascores[:,i])\n",
    "        PROD_sig[i] = np.prod(new_sig_ascores[:,i])\n",
    "        AVG_sig[i] = np.average(new_sig_ascores[:,i])\n",
    "\n",
    "    for i in range(nbkg):\n",
    "        AND_bkg[i] = min(new_bkg_ascores[:,i])\n",
    "        OR_bkg[i] = max(new_bkg_ascores[:,i])\n",
    "        PROD_bkg[i] = np.prod(new_bkg_ascores[:,i])\n",
    "        AVG_bkg[i] = np.average(new_bkg_ascores[:,i])\n",
    "    \n",
    "    if calc_type == 'AND':\n",
    "        AND_auc = determine_auc(AND_bkg, AND_sig)\n",
    "        if resultname != False:\n",
    "            print(\"Saving scores to \",resultname)\n",
    "            np.savetxt(resultname.replace('XXX','AND'), AND_sig)\n",
    "        return AND_auc\n",
    "    if calc_type == 'OR':\n",
    "        OR_auc = determine_auc(OR_bkg, OR_sig)\n",
    "        \n",
    "        if resultname != False:\n",
    "            print(\"Saving scores to \",resultname)\n",
    "            np.savetxt(resultname.replace('XXX','OR'), OR_sig)\n",
    "        return OR_auc\n",
    "    if calc_type == 'AVG':\n",
    "        AVG_auc = determine_auc(AVG_bkg, AVG_sig)\n",
    "        if resultname != False:\n",
    "            print(\"Saving scores to \",resultname)\n",
    "            np.savetxt(resultname.replace('XXX','AVG'), AVG_sig)\n",
    "        return AVG_auc\n",
    "    if calc_type == 'PROD':\n",
    "        PROD_auc = determine_auc(PROD_bkg, PROD_sig)\n",
    "        if resultname != False:\n",
    "            print(\"Saving scores to \",resultname)\n",
    "            np.savetxt(resultname.replace('XXX','PROD'), PROD_sig)\n",
    "        return PROD_auc\n",
    "    \n",
    "    AND_auc = determine_auc(AND_bkg, AND_sig)\n",
    "    OR_auc = determine_auc(OR_bkg, OR_sig)\n",
    "    AVG_auc = determine_auc(AVG_bkg, AVG_sig)\n",
    "    PROD_auc = determine_auc(PROD_bkg, PROD_sig)\n",
    "    \n",
    "    if resultname != False:\n",
    "        print(\"Saving scores to \",resultname)\n",
    "        np.savetxt(resultname.replace('XXX','AND'), AND_sig)\n",
    "        np.savetxt(resultname.replace('XXX','OR'), OR_sig)\n",
    "        np.savetxt(resultname.replace('XXX','PROD'), PROD_sig)\n",
    "        np.savetxt(resultname.replace('XXX','AVG'), AVG_sig)\n",
    "    return AND_auc, OR_auc, AVG_auc, PROD_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fxied taeget\n",
    "fig=plt.figure(figsize=(20,20))\n",
    "i=0\n",
    "j=0\n",
    "\n",
    "legend_titles = ['VAE', 'Flow', 'AND', 'OR', 'PROD', 'AVG']\n",
    "legend_colors = ['blue', 'green', 'purple', 'red', 'orange', 'black']\n",
    "legend_lines = [Line2D([0], [0], color=color, lw=4) for color in legend_colors]\n",
    "font_size = 16\n",
    "\n",
    "calc_types = ['AND', 'OR', 'AVG', 'PROD']\n",
    "\n",
    "for CHANNEL in tqdm(SIG_NAMES):\n",
    "    i+=1\n",
    "    j=0\n",
    "    my_xticks=[]\n",
    "    x=[]\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.title('Channel ' + str(CHANNEL), fontsize=font_size)\n",
    "    for SIGNAL in tqdm(SIG_NAMES[CHANNEL]):\n",
    "        j+=1\n",
    "        AUC_score={}\n",
    "        for calc_type in tqdm(calc_types):\n",
    "            need_calc = True\n",
    "            FNAME = \"combined_result_\" + CHANNEL + \"-\" + str(SIGNAL) + '-' + calc_type\n",
    "            try:\n",
    "                AND_auc, OR_auc, PROD_auc, AVG_auc = np.loadtxt(FNAME)\n",
    "            except:\n",
    "                need_calc = True\n",
    "\n",
    "            FNAME = \"vaef_result_\" + CHANNEL + \"-\" + str(SIGNAL) + '-' + calc_type\n",
    "            try:\n",
    "                AUC_vae, AUC_flow = np.loadtxt(FNAME)\n",
    "            except:\n",
    "                need_calc = True\n",
    "\n",
    "            if need_calc == 1:\n",
    "                calc_name = calc_type\n",
    "\n",
    "                if calc_name == 'AND':\n",
    "                    calc_name = 'min'\n",
    "                elif calc_name == 'OR':\n",
    "                    calc_name = 'max'\n",
    "                elif calc_name == 'AVG':\n",
    "                    calc_name = 'avg'\n",
    "                elif calc_name == 'PROD':\n",
    "                    calc_name = 'prod'\n",
    "\n",
    "                vae_bg = np.loadtxt('data/fixed-mse/fixed_target_combined_scores/'+calc_name+'-bg-'+str(CHANNEL)+'-'+str(SIGNAL))\n",
    "                vae_sig = np.loadtxt('data/fixed-mse/fixed_target_combined_scores/'+calc_name+'-sig-'+str(CHANNEL)+'-'+str(SIGNAL))\n",
    "\n",
    "                flow_bg = np.loadtxt('data/flow/scores_effenc_final_'+str(CHANNEL)+'_bg.csv')\n",
    "                flow_sig = np.loadtxt('data/flow/scores_effenc_final_'+str(CHANNEL)+'_'+str(SIGNAL)+'.csv')\n",
    "\n",
    "                bg_notinf = np.isfinite(flow_bg)\n",
    "                sig_notinf = np.isfinite(flow_sig)\n",
    "                \n",
    "\n",
    "                vae_bg = vae_bg[bg_notinf]\n",
    "                flow_bg = flow_bg[bg_notinf]\n",
    "                vae_sig = vae_sig[sig_notinf]\n",
    "                flow_sig = flow_sig[sig_notinf]\n",
    "\n",
    "                max_score = np.amax(np.concatenate((vae_bg, vae_sig)))\n",
    "                min_score = np.amin(np.concatenate((vae_bg, vae_sig)))\n",
    "                vae_bg_scores = (vae_bg - min_score)/(max_score - min_score)\n",
    "                vae_sig_scores = (vae_sig - min_score)/(max_score - min_score)   \n",
    "\n",
    "                max_score = np.amax(np.concatenate((flow_bg, flow_sig)))\n",
    "                min_score = np.amin(np.concatenate((flow_bg, flow_sig)))\n",
    "                flow_bg_scores = 1-(flow_bg - min_score)/(max_score - min_score)\n",
    "                flow_sig_scores = 1-(flow_sig - min_score)/(max_score - min_score)\n",
    "                \n",
    "                save_individual_scores = False\n",
    "                if SIGNAL == 999:\n",
    "                    save_individual_scores = \"secret999_results/Combined-FixedTarget-Flow-XXX_FixedTargetMSE_FlowLikelihood-chan\"+str(CHANNEL)+\".csv\"\n",
    "                    print(\"Saving to \",save_individual_scores)\n",
    "\n",
    "                FNAME = \"combined_result_\" + CHANNEL + \"-\" + str(SIGNAL) + '-' + calc_type\n",
    "                try:\n",
    "                    AUC_score[calc_type] = np.loadtxt(FNAME)\n",
    "                except:\n",
    "                    AUC_score[calc_type] = calculate_metrics(save_individual_scores, vae_bg_scores, vae_sig_scores, flow_bg_scores, flow_sig_scores, calc_type)\n",
    "                    np.savetxt(FNAME, AUC_score[calc_type])\n",
    "\n",
    "                FNAME = \"vae_result_\" + CHANNEL + \"-\" + str(SIGNAL) + '-' + calc_type\n",
    "                try:\n",
    "                    AUC_score['VAE'] = np.loadtxt(FNAME)\n",
    "                except:\n",
    "                    AUC_score['VAE'] = determine_auc(vae_bg_scores, vae_sig_scores)\n",
    "                    np.savetxt(FNAME, [AUC_score['VAE']])\n",
    "                \n",
    "        FNAME = \"flow_result_\" + CHANNEL + \"-\" + str(SIGNAL) + '-' + calc_type\n",
    "        try:\n",
    "            AUC_score['FLOW'] = np.loadtxt(FNAME)\n",
    "        except:\n",
    "            AUC_score['FLOW'] = determine_auc(flow_bg_scores, flow_sig_scores)\n",
    "            np.savetxt(FNAME, [AUC_score['FLOW']])\n",
    "        \n",
    "        plt.scatter(j, AUC_score['VAE'][0], color=legend_colors[0])\n",
    "        plt.scatter(j, AUC_score['FLOW'][0], color=legend_colors[1])\n",
    "        plt.scatter(j, AUC_score['AND'][0], color=legend_colors[2])\n",
    "        plt.scatter(j, AUC_score['OR'][0], color=legend_colors[3])\n",
    "        plt.scatter(j, AUC_score['PROD'][0], color=legend_colors[4])\n",
    "        plt.scatter(j, AUC_score['AVG'][0], color=legend_colors[5])\n",
    "        \n",
    "        my_xticks.append(SIG_NAMES[CHANNEL][SIGNAL])\n",
    "        x.append(j)\n",
    "    plt.xticks(x, my_xticks, rotation=90, fontsize=font_size)\n",
    "    if i == 1 or i == 3:\n",
    "        plt.ylabel(\"AUC\", fontsize=font_size)\n",
    "    if i == 1:\n",
    "        plt.legend(\n",
    "            legend_lines, \n",
    "            legend_titles, \n",
    "            fontsize=font_size, \n",
    "            loc=\"upper right\", \n",
    "            ncol=6,\n",
    "            bbox_to_anchor=(0.3, 1.05, 1, 0.1),\n",
    "            borderaxespad=0, \n",
    "            frameon=False\n",
    "        )\n",
    "\n",
    "fig.subplots_adjust(hspace=0.6)\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "#     sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_result(row):\n",
    "    f = open(\"combined_scores.csv\", \"a+\")\n",
    "    f.write(','.join(row) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED TARGETs\n",
    "for CHANNEL in SIG_NAMES:\n",
    "    for SIGNAL in (SIG_NAMES[CHANNEL]):\n",
    "        if SIGNAL == 'Secret':\n",
    "            continue\n",
    "        FNAME = \"combined_result_\" + CHANNEL + \"-\" + str(SIGNAL)\n",
    "        AND_auc = np.loadtxt(FNAME + '-AND')\n",
    "        OR_auc = np.loadtxt(FNAME + '-OR')\n",
    "        AVG_auc = np.loadtxt(FNAME + '-AVG')\n",
    "        PROD_auc = np.loadtxt(FNAME + '-PROD')\n",
    "        \n",
    "        signal = SIG_NAMES[CHANNEL][SIGNAL]\n",
    "        algorithm = 'Combined-FixedTarget-Flow-'\n",
    "        anomaly_score = 'Fixed target MSE + Flow Likelihood'\n",
    "        channel = CHANNEL\n",
    "        \n",
    "        append_to_result([signal, algorithm+'AND',anomaly_score, channel, \"{:.2f}\".format(AND_auc[0]), \"{:.2f}\".format(AND_auc[1]), \"{:.2f}\".format(AND_auc[2]), \"{:.2f}\".format(AND_auc[3])])\n",
    "        append_to_result([signal, algorithm+'OR',anomaly_score, channel, \"{:.2f}\".format(OR_auc[0]), \"{:.2f}\".format(OR_auc[1]), \"{:.2f}\".format(OR_auc[2]), \"{:.2f}\".format(OR_auc[3])])\n",
    "        append_to_result([signal, algorithm+'PROD',anomaly_score, channel, \"{:.2f}\".format(PROD_auc[0]), \"{:.2f}\".format(PROD_auc[1]), \"{:.2f}\".format(PROD_auc[2]), \"{:.2f}\".format(PROD_auc[3])])\n",
    "        append_to_result([signal, algorithm+'AVG',anomaly_score, channel, \"{:.2f}\".format(AVG_auc[0]), \"{:.2f}\".format(AVG_auc[1]), \"{:.2f}\".format(AVG_auc[2]), \"{:.2f}\".format(AVG_auc[3])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
