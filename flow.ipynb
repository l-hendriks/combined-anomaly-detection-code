{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability.python.bijectors import affine_scalar\n",
    "import math as m\n",
    "import random as r\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "import h5py\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigh https://github.com/keras-team/keras/issues/4875\n",
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfb = tfp.bijectors\n",
    "tfk = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG_NAMES = {\n",
    "    '1': {\n",
    "        1: \"stop2b1000_neutralino300\",\n",
    "        2: \"glgl1400_neutralino1100\",\n",
    "        28: \"monojet_Zp2000.0_DM_50.0\",\n",
    "        29: \"glgl1600_neutralino800\",\n",
    "        30: \"monotop_200_A\",\n",
    "        31: \"stlp_st1000\",\n",
    "        32: \"sqsq_sq1800_neut800\",\n",
    "        33: \"sqsq1_sq1400_neut800\",\n",
    "        999: \"Secret\"\n",
    "    },\n",
    "    '2a': {\n",
    "        25: \"chaneut_cha250_neut150\",\n",
    "        26: \"chaneut_cha400_neut200\",\n",
    "        27: \"pp24mt_50\",\n",
    "        28: \"pp23mt_50\",\n",
    "        29: \"gluino_1000.0_neutralino_1.0\",\n",
    "        30: \"chaneut_cha200_neut50\",\n",
    "        31: \"chaneut_cha300_neut100\",\n",
    "        999: \"Secret\"\n",
    "    },\n",
    "    '2b': {\n",
    "        1: \"pp24mt_50\",\n",
    "        2: \"chaneut_cha200_neut50\",\n",
    "        3: \"stlp_st1000\",\n",
    "        4: \"chacha_cha600_neut200\",\n",
    "        5: \"pp23mt_50\",\n",
    "        6: \"chaneut_cha250_neut150\",\n",
    "        7: \"chacha_cha400_neut60\",\n",
    "        34: \"gluino_1000.0_neutralino_1.0\",\n",
    "        35: \"chacha_cha300_neut140\",\n",
    "        999: \"Secret\"\n",
    "    },\n",
    "    '3': {\n",
    "        1: \"glgl1600_neutralino800\",\n",
    "        2: \"monojet_Zp2000.0_DM_50.0\",\n",
    "        3: \"gluino_1000.0_neutralino_1.0\",\n",
    "        4: \"stop2b1000_neutralino300\",\n",
    "        5: \"sqsq1_sq1400_neut800\",\n",
    "        6: \"monotop_200_A\",\n",
    "        7: \"monoV_Zp2000.0_DM_1.0\",\n",
    "        8: \"stlp_st1000\",\n",
    "        34: \"sqsq_sq1800_neut800\",\n",
    "        35: \"glgl1400_neutralino1100\",\n",
    "        999: \"Secret\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIG_TYPES = {\n",
    "    '1': [1, 2, 28, 29, 30, 31, 32, 33,999],\n",
    "    '2a': [25, 26, 27, 28, 29, 30, 31,999],\n",
    "    '2b': [1,2,3,4,5,6,7, 34,35,999],\n",
    "    '3': [1,2,3,4,5,6,7,8,34,35,999]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "class types:\n",
    "0 none\n",
    "1 j\n",
    "2 b\n",
    "3 g\n",
    "4 e+\n",
    "5 e-\n",
    "6 m+\n",
    "7 m-\n",
    "\"\"\"\n",
    "\n",
    "CLASS = {\n",
    "    'none': 0.,\n",
    "    'j': 1.,\n",
    "    'b': 2.,\n",
    "    'g': 3.,\n",
    "    'e+': 4.,\n",
    "    'e-': 5.,\n",
    "    'm+': 6.,\n",
    "    'm-': 7.\n",
    "}\n",
    "MAX_JET = 7\n",
    "MAX_LEP = 4\n",
    "\n",
    "CHANNELS = ['1', '2a', '2b', '3']\n",
    "n_epochs = 100\n",
    "\n",
    "def update_points(x_reg, x_class, energies):\n",
    "    \n",
    "    MET = x_reg[0]\n",
    "    METphi = x_reg[1]\n",
    "    num_j = sum(x_class == CLASS['j'])\n",
    "    num_b = sum(x_class == CLASS['b'])\n",
    "    num_g = sum(x_class == CLASS['g'])\n",
    "    num_ep = sum(x_class == CLASS['e+'])\n",
    "    num_em = sum(x_class == CLASS['e-'])\n",
    "    num_mp = sum(x_class == CLASS['m+'])\n",
    "    num_mm = sum(x_class == CLASS['m-'])\n",
    "    \n",
    "    num_j = np.random.uniform(num_j-0.5, num_j+0.5)\n",
    "    num_b = np.random.uniform(num_b-0.5, num_b+0.5)\n",
    "    num_g = np.random.uniform(num_g-0.5, num_g+0.5)\n",
    "    num_ep = np.random.uniform(num_ep-0.5, num_ep+0.5)\n",
    "    num_em = np.random.uniform(num_em-0.5, num_em+0.5)\n",
    "    num_mp = np.random.uniform(num_mp-0.5, num_mp+0.5)\n",
    "    num_mm = np.random.uniform(num_mm-0.5, num_mm+0.5)\n",
    "    \n",
    "    # Get jets\n",
    "    jets_ar = np.random.uniform(-6, -3, MAX_JET * 5)\n",
    "    jets_indices = np.where((x_class == CLASS['j']) | (x_class == CLASS['b']))[0]\n",
    "        \n",
    "    it=0\n",
    "    while it < np.min((len(jets_indices), MAX_JET)):\n",
    "        i = jets_indices[it]\n",
    "        reg_vals = x_reg[i*4:i*4+4]\n",
    "        reg_type = x_class[i]\n",
    "        jets_ar[it*5] = np.random.uniform(-1, 0) if reg_type == CLASS['b'] else np.random.uniform(0, 1)\n",
    "        jets_ar[it*5+1:it*5+5] = reg_vals\n",
    "        it+=1\n",
    "        \n",
    "    # Get leptons\n",
    "    lep_ar = np.random.uniform(-6, -3, MAX_LEP * 5)\n",
    "    lep_indices = np.where((x_class == CLASS['e+']) | (x_class == CLASS['e-']) | (x_class == CLASS['g']) | (x_class == CLASS['m+']) | (x_class == CLASS['m-']))[0]\n",
    "        \n",
    "    it=0\n",
    "    while it < np.min((len(lep_indices), MAX_LEP)):\n",
    "        i = lep_indices[it]\n",
    "        reg_vals = x_reg[i*4:i*4+4]\n",
    "        reg_type = x_class[i]\n",
    "        \n",
    "        if reg_type == CLASS['m-']:\n",
    "            lep_ar[it*5] = np.random.uniform(-2.5, -1.5)\n",
    "        if reg_type == CLASS['e-']:\n",
    "            lep_ar[it*5] = np.random.uniform(-1.5, -0.5)\n",
    "        if reg_type == CLASS['g']:\n",
    "            lep_ar[it*5] = np.random.uniform(-0.5, 0.5)\n",
    "        if reg_type == CLASS['e+']:\n",
    "            lep_ar[it*5] = np.random.uniform(0.5, 1.5)\n",
    "        if reg_type == CLASS['m+']:\n",
    "            lep_ar[it*5] = np.random.uniform(1.5, 2.5)\n",
    "                         \n",
    "        lep_ar[it*5+1:it*5+5] = reg_vals\n",
    "        it+=1\n",
    "    \n",
    "    row = [MET, METphi, num_j, num_b, num_g, num_ep, num_em, num_mp, num_mm]\n",
    "#     row.extend(list(jets_ar))\n",
    "#     row.extend(list(lep_ar))\n",
    "    return row\n",
    "\n",
    "def get_data(channel):\n",
    "    train_h5 = h5py.File('training_chan'+str(channel)+'.h5', 'r')\n",
    "    train_raw_reg = np.array(train_h5['reg'], dtype=np.float64)\n",
    "    train_raw_class = np.array(train_h5['clas'], dtype=np.float64)\n",
    "    energies = list(i*4+2 for i in range(int((train_raw_reg.shape[1]-1)/4)))\n",
    "    \n",
    "    train = []\n",
    "    for i in tqdm(range(len(train_raw_reg))):\n",
    "        train.append(update_points(train_raw_reg[i], train_raw_class[i,:,0], energies))\n",
    "    train = np.array(train)\n",
    "    \n",
    "    print(train.shape,energies)\n",
    "    \n",
    "    test_h5 = h5py.File('testing_chan'+str(channel)+'.h5', 'r')\n",
    "    secret_h5 = h5py.File('inference_chan'+str(channel)+'.h5', 'r')\n",
    "    \n",
    "    test_bg_reg = []\n",
    "    \n",
    "    test_sig_reg = []\n",
    "    signal_types = []\n",
    "\n",
    "    \n",
    "    types = test_h5['type']\n",
    "    reg = test_h5['reg']\n",
    "    clas = test_h5['clas']\n",
    "    \n",
    "    for i in tqdm(range(len(types))):\n",
    "        typ = types[i]\n",
    "        reg_updated = update_points(reg[i], clas[i,:,0], energies)\n",
    "        if typ in SIG_TYPES[channel]:\n",
    "            # signal\n",
    "            test_sig_reg.append(reg_updated)\n",
    "            signal_types.append(typ)\n",
    "        else:\n",
    "            # bg\n",
    "            test_bg_reg.append(reg_updated)\n",
    "            \n",
    "    # Append secret set\n",
    "    secret_clas = secret_h5['clas']\n",
    "    secret_reg = secret_h5['reg']\n",
    "    for i in tqdm(range(len(secret_reg))):\n",
    "        signal_types.append(999)\n",
    "        reg_updated = update_points(secret_reg[i], secret_clas[i,:,0], energies)\n",
    "        test_sig_reg.append(reg_updated)\n",
    "    \n",
    "    test_bg = np.array(test_bg_reg, dtype=np.float64)\n",
    "    test_sig = np.array(test_sig_reg, dtype=np.float64)\n",
    "        \n",
    "    return train, test_bg, test_sig, signal_types\n",
    "\n",
    "\n",
    "train, test_bg, test_sig, signal_types = get_data('2a')\n",
    "print(train[0])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def batched_log_prob(dist, inputs, batch_size=1000):\n",
    "    num_batches = m.ceil(inputs.shape[0] / batch_size)\n",
    "    result = []\n",
    "    for b in range(num_batches):\n",
    "        result.extend(dist.log_prob(inputs[b*batch_size:(b+1)*batch_size]))\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "    \n",
    "CHANNELS=['3']\n",
    "for channel_num in CHANNELS:\n",
    "    background_train_unscaled, background_test_unscaled, signal_unscaled, signal_types = get_data(channel_num)\n",
    "    \n",
    "    # Scale to unit box\n",
    "    epsilon = 1e-4 # Small factor to ensure no training points are exactly on the edge of phase space\n",
    "    max = np.amax( np.concatenate((background_train_unscaled, background_test_unscaled, signal_unscaled)), axis=0 )*(1+epsilon) + epsilon \n",
    "    min = np.amin( np.concatenate((background_train_unscaled, background_test_unscaled, signal_unscaled)), axis=0 )*(1+epsilon) - epsilon\n",
    "    background_train = (background_train_unscaled - min)/(max - min)\n",
    "    background_test = (background_test_unscaled - min)/(max - min)\n",
    "    signal_flat = (signal_unscaled - min)/(max - min)\n",
    "\n",
    "    event_dim = background_train.shape[1]\n",
    "\n",
    "    n_RQS_knots = 35 # Number of knots in RQS transform\n",
    "    n_made_layers = 7 # Number of layers in every made network\n",
    "    n_made_units = 200 # Number of units in every layer of the made network\n",
    "    n_flow_layers = 11 # Number of layers in the flow\n",
    "    # Training parameters\n",
    "    batch_size = 512\n",
    "\n",
    "    def create_bijector_fn(made=None):\n",
    "        # If no MADE is provided, create a default one\n",
    "        hidden_units_ = [n_made_units]*n_made_layers\n",
    "        if made is None:\n",
    "            made = tfb.AutoregressiveNetwork(params=3*n_RQS_knots-1,\n",
    "                                             input_order='random',\n",
    "                                             activation=tf.nn.leaky_relu,\n",
    "                                             hidden_units=hidden_units_,\n",
    "                                             dtype=tf.float64)\n",
    "        # Define the custom_bijector_fn\n",
    "        # This function will use the provided (or just created) MADE internally due to scope\n",
    "        def custom_bijector_fn(x):\n",
    "            bw_pre, bh_pre, ks_pre = tf.split(made(x), [n_RQS_knots, n_RQS_knots, n_RQS_knots-1], axis=-1)\n",
    "            bw = tf.math.softmax(bw_pre, axis=-1) * (1 - n_RQS_knots*1e-3) + 1e-3\n",
    "            bh = tf.math.softmax(bh_pre, axis=-1) * (1 - n_RQS_knots*1e-3) + 1e-3\n",
    "            ks = tf.math.softplus(ks_pre) + 1e-3\n",
    "            return tfb.RationalQuadraticSpline(bin_widths=bw, bin_heights=bh, knot_slopes=ks, range_min=0.)\n",
    "        # Return handle to the just defined function\n",
    "        return custom_bijector_fn\n",
    "\n",
    "    # Base distribution\n",
    "    dist = tfd.Uniform(low=np.float64(0.), high=np.float64(1.))\n",
    "\n",
    "    # Loop for number of flow layers\n",
    "    for i in range(n_flow_layers):\n",
    "        event_shape_ = [event_dim] if i==0 else None\n",
    "        # Replace the distribution with an additional layer\n",
    "        dist = tfd.TransformedDistribution(\n",
    "            distribution = dist, \n",
    "            bijector = tfb.MaskedAutoregressiveFlow(bijector_fn = create_bijector_fn()),\n",
    "            event_shape = event_shape_)\n",
    "\n",
    "    # Construct model\n",
    "    x_ = tfk.layers.Input(shape=(event_dim,), dtype=tf.float64)\n",
    "    log_prob = dist.log_prob(x_)\n",
    "    model = tfk.Model(x_, log_prob)\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(epsilon=1e-3),\n",
    "                  loss=lambda _, log_prob: tf.clip_by_value(-log_prob, -1e9, 100))\n",
    "\n",
    "    epoch_num = n_epochs\n",
    "    if channel_num == '3':\n",
    "        epoch_num = 10\n",
    "    \n",
    "    losses = model.fit(x = background_train, y = np.zeros((background_train.shape[0], 0), dtype=np.float32), batch_size=batch_size, epochs=epoch_num, shuffle=True, verbose=True)\n",
    "    np.savetxt('effenc_small_loss_' + channel_num, losses.history['loss'])\n",
    "\n",
    "#     Compute log probs for signal and background\n",
    "\n",
    "    \n",
    "    logprobs_background = batched_log_prob(dist, background_test)\n",
    "    logprobs_background[logprobs_background == -np.inf] = np.amin(logprobs_background[logprobs_background != -np.inf]) + np.sign(logprobs_background[logprobs_background == -np.inf])*1e-4 # Kick out spurious -inf \n",
    "    \n",
    "    # For every signal separately\n",
    "    signals = {}\n",
    "    for typ in np.unique(signal_types):\n",
    "        signals[typ] = []\n",
    "    for i in range(len(signal_flat)):\n",
    "        signals[signal_types[i]].append(signal_flat[i])\n",
    "        \n",
    "    model.save_weights('model_weights_effenc_small_flow_' + channel_num)\n",
    "#     model.load_weights('model_weights_effenc_flow_' + channel_num)\n",
    "        \n",
    "    fpr_list = {}\n",
    "    tpr_list = {}\n",
    "    logprobs_signal_list = {}\n",
    "    roc_auc_list = {}\n",
    "    for signal_type in signals:\n",
    "        signal = np.array(signals[signal_type])\n",
    "        sig_name = SIG_NAMES[channel_num][signal_type]\n",
    "    \n",
    "        logprobs_signal = batched_log_prob(dist, signal)\n",
    "        logprobs_signal[logprobs_signal == -np.inf] = np.amin(logprobs_signal[logprobs_signal != -np.inf]) + np.sign(logprobs_signal[logprobs_signal == -np.inf])*1e-4 # Kick out spurious -inf \n",
    "\n",
    "        # Normalize logprobs to a score\n",
    "        max_log_prob = np.amax(np.concatenate((logprobs_background, logprobs_signal)))\n",
    "        min_log_prob = np.amin(np.concatenate((logprobs_background, logprobs_signal)))\n",
    "        background_scores = (logprobs_background - min_log_prob)/(max_log_prob - min_log_prob)\n",
    "        signal_scores = (logprobs_signal - min_log_prob)/(max_log_prob - min_log_prob)\n",
    "        \n",
    "        print(background_test_unscaled[0])\n",
    "        print(signal_unscaled[0])\n",
    "        \n",
    "        np.savetxt('scores_effenc_final_small_'+str(channel_num)+'_bg.csv', background_scores)\n",
    "        np.savetxt('scores_effenc_final_small_'+str(channel_num)+'_'+str(signal_type)+'.csv', signal_scores)\n",
    "\n",
    "\n",
    "        # Concatenate to total scores and labels\n",
    "        total_scores = np.concatenate((background_scores, signal_scores))\n",
    "        background_labels = np.ones_like(background_scores)\n",
    "        signal_labels = np.zeros_like(signal_scores)\n",
    "        total_labels = np.concatenate((background_labels, signal_labels))\n",
    "\n",
    "        # Compute roc curve\n",
    "        fpr, tpr, thresholds = roc_curve(total_labels, total_scores)\n",
    "        roc_auc = roc_auc_score(y_true=total_labels, y_score=total_scores)\n",
    "        print(\"Area under ROC curve for \" + str(sig_name) + \" is \", roc_auc)\n",
    "        \n",
    "        fpr_list[signal_type] = fpr\n",
    "        tpr_list[signal_type] = tpr\n",
    "        logprobs_signal_list[signal_type] = logprobs_signal\n",
    "        roc_auc_list[signal_type] = roc_auc\n",
    "\n",
    "    \n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    for key in fpr_list:\n",
    "        sig_name = SIG_NAMES[channel_num][key]\n",
    "        plt.plot(fpr_list[key], tpr_list[key], label='ROC curve '+ str(sig_name) +' (area = %0.3f)' % roc_auc_list[key])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig.savefig(\"effenc_small_ROC\"+channel_num+\".png\", bbox_inches='tight', dpi=150)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.xlabel('Log_Likelihood')\n",
    "    for key in logprobs_signal_list:\n",
    "        sig_name = SIG_NAMES[channel_num][key]\n",
    "        plt.hist(logprobs_signal_list[key], bins=25, alpha=0.5, density=True, label=\"signal \" + str(sig_name))\n",
    "    plt.hist(logprobs_background, bins=25, alpha=0.5, density=True, label=\"background\")\n",
    "    plt.legend(loc='lower left')\n",
    "    fig.savefig(\"effenc_small_likelihood_histogram\"+channel_num+\".png\", bbox_inches='tight', dpi=150)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
